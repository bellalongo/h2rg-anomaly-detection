{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7d09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993c7b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 13:44:18,267 - WARNING - Test directory test does not exist\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TestDataLoader' object has no attribute 'difference_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 454\u001b[39m\n\u001b[32m    450\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDetailed report saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 424\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    421\u001b[39m loader = TestDataLoader(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# or whatever your test directory is\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# Load all exposures\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m exposures = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_all_exposures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(exposures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m exposures\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    427\u001b[39m \u001b[38;5;66;03m# Get summary\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mTestDataLoader.load_all_exposures\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    107\u001b[39m exposure_ids = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Extract exposure IDs from filenames\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_list \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdifference_files\u001b[49m, \u001b[38;5;28mself\u001b[39m.patch_files, \u001b[38;5;28mself\u001b[39m.temporal_files, \u001b[38;5;28mself\u001b[39m.metadata_files]:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[32m    112\u001b[39m         \u001b[38;5;66;03m# Extract exposure ID (assumes format: exposureID_datatype.h5)\u001b[39;00m\n\u001b[32m    113\u001b[39m         parts = file_path.stem.split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'TestDataLoader' object has no attribute 'difference_files'"
     ]
    }
   ],
   "source": [
    "class TestDataLoader:\n",
    "    \"\"\"\n",
    "    Loads and analyzes H5py files generated during test mode runs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, test_dir: str = \"test\"):\n",
    "        \"\"\"\n",
    "        Initialize the test data loader\n",
    "        \n",
    "        Args:\n",
    "            test_dir: Directory containing test output files\n",
    "        \"\"\"\n",
    "        self.test_dir = Path(test_dir)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize data containers\n",
    "        self.exposures = {}\n",
    "        self.summary_stats = {}\n",
    "        \n",
    "        # Check if test directory exists\n",
    "        if not self.test_dir.exists():\n",
    "            self.logger.warning(f\"Test directory {self.test_dir} does not exist\")\n",
    "            return\n",
    "            \n",
    "        self._discover_test_files()\n",
    "    \n",
    "    def _discover_test_files(self):\n",
    "        \"\"\"Discover and catalog all test files\"\"\"\n",
    "        self.logger.info(f\"Discovering test files in {self.test_dir}\")\n",
    "        \n",
    "        # Look for different data types\n",
    "        self.difference_files = list((self.test_dir / \"raw_differences\").glob(\"*_differences.h5\")) if (self.test_dir / \"raw_differences\").exists() else []\n",
    "        self.patch_files = list((self.test_dir / \"patches\").glob(\"*_patches_*.h5\")) if (self.test_dir / \"patches\").exists() else []\n",
    "        self.temporal_files = list((self.test_dir / \"temporal_analysis\").glob(\"*_temporal.h5\")) if (self.test_dir / \"temporal_analysis\").exists() else []\n",
    "        self.metadata_files = list((self.test_dir / \"metadata\").glob(\"*_metadata.json\")) if (self.test_dir / \"metadata\").exists() else []\n",
    "        \n",
    "        self.logger.info(f\"Found {len(self.difference_files)} difference files\")\n",
    "        self.logger.info(f\"Found {len(self.patch_files)} patch files\")\n",
    "        self.logger.info(f\"Found {len(self.temporal_files)} temporal files\")\n",
    "        self.logger.info(f\"Found {len(self.metadata_files)} metadata files\")\n",
    "    \n",
    "    def load_exposure_data(self, exposure_id: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Load all data for a specific exposure\n",
    "        \n",
    "        Args:\n",
    "            exposure_id: ID of the exposure to load\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing all data for the exposure\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            'exposure_id': exposure_id,\n",
    "            'differences': None,\n",
    "            'patches': {},\n",
    "            'temporal': None,\n",
    "            'metadata': None\n",
    "        }\n",
    "        \n",
    "        # Load difference data\n",
    "        diff_file = self.test_dir / \"raw_differences\" / f\"{exposure_id}_differences.h5\"\n",
    "        if diff_file.exists():\n",
    "            with h5py.File(diff_file, 'r') as f:\n",
    "                data['differences'] = {\n",
    "                    'data': f['differences'][:],\n",
    "                    'frame_times': f['frame_times'][:] if 'frame_times' in f else None,\n",
    "                    'reference_frame': f['reference_frame'][:] if 'reference_frame' in f else None,\n",
    "                    'attrs': dict(f.attrs)\n",
    "                }\n",
    "        \n",
    "        # Load patch data (multiple patch sizes)\n",
    "        patch_dir = self.test_dir / \"patches\"\n",
    "        if patch_dir.exists():\n",
    "            for patch_file in patch_dir.glob(f\"{exposure_id}_patches_*.h5\"):\n",
    "                # Extract patch size from filename\n",
    "                patch_size = patch_file.stem.split('_')[-1]\n",
    "                with h5py.File(patch_file, 'r') as f:\n",
    "                    data['patches'][patch_size] = {\n",
    "                        'patches': f['patches'][:],\n",
    "                        'positions': f['positions'][:] if 'positions' in f else None,\n",
    "                        'frame_indices': f['frame_indices'][:] if 'frame_indices' in f else None,\n",
    "                        'anomaly_scores': f['anomaly_scores'][:] if 'anomaly_scores' in f else None,\n",
    "                        'attrs': dict(f.attrs)\n",
    "                    }\n",
    "        \n",
    "        # Load temporal analysis data\n",
    "        temporal_file = self.test_dir / \"temporal_analysis\" / f\"{exposure_id}_temporal.h5\"\n",
    "        if temporal_file.exists():\n",
    "            with h5py.File(temporal_file, 'r') as f:\n",
    "                data['temporal'] = {\n",
    "                    'temporal_stats': f['temporal_stats'][:] if 'temporal_stats' in f else None,\n",
    "                    'frame_statistics': f['frame_statistics'][:] if 'frame_statistics' in f else None,\n",
    "                    'attrs': dict(f.attrs)\n",
    "                }\n",
    "        \n",
    "        # Load metadata\n",
    "        metadata_file = self.test_dir / \"metadata\" / f\"{exposure_id}_metadata.json\"\n",
    "        if metadata_file.exists():\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                data['metadata'] = json.load(f)\n",
    "        \n",
    "        self.exposures[exposure_id] = data\n",
    "        return data\n",
    "    \n",
    "    def load_all_exposures(self) -> Dict:\n",
    "        \"\"\"Load data for all discovered exposures\"\"\"\n",
    "        exposure_ids = set()\n",
    "        \n",
    "        # Extract exposure IDs from filenames\n",
    "        for file_list in [self.difference_files, self.patch_files, self.temporal_files, self.metadata_files]:\n",
    "            for file_path in file_list:\n",
    "                # Extract exposure ID (assumes format: exposureID_datatype.h5)\n",
    "                parts = file_path.stem.split('_')\n",
    "                if len(parts) >= 2:\n",
    "                    exposure_id = '_'.join(parts[:-1])  # Everything except the last part\n",
    "                    if 'patches' in parts:\n",
    "                        # For patch files: exposureID_patches_size.h5\n",
    "                        exposure_id = '_'.join(parts[:-2])\n",
    "                    exposure_ids.add(exposure_id)\n",
    "        \n",
    "        for exposure_id in exposure_ids:\n",
    "            self.load_exposure_data(exposure_id)\n",
    "        \n",
    "        return self.exposures\n",
    "    \n",
    "    def get_data_summary(self) -> Dict:\n",
    "        \"\"\"Get summary statistics of loaded data\"\"\"\n",
    "        if not self.exposures:\n",
    "            self.load_all_exposures()\n",
    "        \n",
    "        summary = {\n",
    "            'total_exposures': len(self.exposures),\n",
    "            'exposures': {},\n",
    "            'overall_stats': {\n",
    "                'total_difference_frames': 0,\n",
    "                'total_patches': 0,\n",
    "                'patch_sizes': set(),\n",
    "                'datasets': set()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for exp_id, data in self.exposures.items():\n",
    "            exp_summary = {\n",
    "                'has_differences': data['differences'] is not None,\n",
    "                'has_patches': len(data['patches']) > 0,\n",
    "                'has_temporal': data['temporal'] is not None,\n",
    "                'has_metadata': data['metadata'] is not None\n",
    "            }\n",
    "            \n",
    "            if data['differences']:\n",
    "                diff_shape = data['differences']['data'].shape\n",
    "                exp_summary['difference_shape'] = diff_shape\n",
    "                exp_summary['num_frames'] = diff_shape[0] if len(diff_shape) > 2 else 1\n",
    "                summary['overall_stats']['total_difference_frames'] += exp_summary['num_frames']\n",
    "            \n",
    "            if data['patches']:\n",
    "                exp_summary['patch_sizes'] = list(data['patches'].keys())\n",
    "                summary['overall_stats']['patch_sizes'].update(exp_summary['patch_sizes'])\n",
    "                \n",
    "                patch_count = sum(data['patches'][size]['patches'].shape[0] \n",
    "                                 for size in data['patches'])\n",
    "                exp_summary['total_patches'] = patch_count\n",
    "                summary['overall_stats']['total_patches'] += patch_count\n",
    "            \n",
    "            if data['metadata']:\n",
    "                dataset_type = data['metadata'].get('dataset_type', 'unknown')\n",
    "                exp_summary['dataset_type'] = dataset_type\n",
    "                summary['overall_stats']['datasets'].add(dataset_type)\n",
    "            \n",
    "            summary['exposures'][exp_id] = exp_summary\n",
    "        \n",
    "        # Convert sets to lists for JSON serialization\n",
    "        summary['overall_stats']['patch_sizes'] = list(summary['overall_stats']['patch_sizes'])\n",
    "        summary['overall_stats']['datasets'] = list(summary['overall_stats']['datasets'])\n",
    "        \n",
    "        self.summary_stats = summary\n",
    "        return summary\n",
    "    \n",
    "    def analyze_differences(self, exposure_id: str = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze frame difference data\n",
    "        \n",
    "        Args:\n",
    "            exposure_id: Specific exposure to analyze, or None for all\n",
    "            \n",
    "        Returns:\n",
    "            Analysis results\n",
    "        \"\"\"\n",
    "        if exposure_id:\n",
    "            exposures_to_analyze = [exposure_id] if exposure_id in self.exposures else []\n",
    "        else:\n",
    "            exposures_to_analyze = list(self.exposures.keys())\n",
    "        \n",
    "        analysis = {}\n",
    "        \n",
    "        for exp_id in exposures_to_analyze:\n",
    "            data = self.exposures[exp_id]\n",
    "            if not data['differences']:\n",
    "                continue\n",
    "                \n",
    "            diff_data = data['differences']['data']\n",
    "            \n",
    "            # Calculate statistics\n",
    "            stats = {\n",
    "                'shape': diff_data.shape,\n",
    "                'mean': float(np.mean(diff_data)),\n",
    "                'std': float(np.std(diff_data)),\n",
    "                'min': float(np.min(diff_data)),\n",
    "                'max': float(np.max(diff_data)),\n",
    "                'median': float(np.median(diff_data)),\n",
    "                'percentiles': {\n",
    "                    '1': float(np.percentile(diff_data, 1)),\n",
    "                    '5': float(np.percentile(diff_data, 5)),\n",
    "                    '95': float(np.percentile(diff_data, 95)),\n",
    "                    '99': float(np.percentile(diff_data, 99))\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Frame-by-frame statistics if multiple frames\n",
    "            if len(diff_data.shape) > 2:\n",
    "                frame_stats = []\n",
    "                for i in range(diff_data.shape[0]):\n",
    "                    frame = diff_data[i]\n",
    "                    frame_stats.append({\n",
    "                        'frame': i,\n",
    "                        'mean': float(np.mean(frame)),\n",
    "                        'std': float(np.std(frame)),\n",
    "                        'rms': float(np.sqrt(np.mean(frame**2)))\n",
    "                    })\n",
    "                stats['frame_stats'] = frame_stats\n",
    "            \n",
    "            analysis[exp_id] = stats\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def plot_difference_analysis(self, exposure_id: str, save_dir: str = None):\n",
    "        \"\"\"\n",
    "        Create plots for difference data analysis\n",
    "        \n",
    "        Args:\n",
    "            exposure_id: Exposure to plot\n",
    "            save_dir: Directory to save plots (optional)\n",
    "        \"\"\"\n",
    "        if exposure_id not in self.exposures:\n",
    "            self.logger.error(f\"Exposure {exposure_id} not loaded\")\n",
    "            return\n",
    "        \n",
    "        data = self.exposures[exposure_id]['differences']\n",
    "        if not data:\n",
    "            self.logger.error(f\"No difference data for exposure {exposure_id}\")\n",
    "            return\n",
    "        \n",
    "        diff_data = data['data']\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle(f'Difference Analysis: {exposure_id}', fontsize=16)\n",
    "        \n",
    "        # Histogram of all pixel values\n",
    "        axes[0, 0].hist(diff_data.flatten(), bins=100, alpha=0.7, edgecolor='black')\n",
    "        axes[0, 0].set_title('Pixel Value Distribution')\n",
    "        axes[0, 0].set_xlabel('Difference Value')\n",
    "        axes[0, 0].set_ylabel('Count')\n",
    "        axes[0, 0].set_yscale('log')\n",
    "        \n",
    "        # Show first frame (or single frame)\n",
    "        first_frame = diff_data[0] if len(diff_data.shape) > 2 else diff_data\n",
    "        im1 = axes[0, 1].imshow(first_frame, cmap='viridis', aspect='auto')\n",
    "        axes[0, 1].set_title('First Difference Frame')\n",
    "        plt.colorbar(im1, ax=axes[0, 1])\n",
    "        \n",
    "        # Show standard deviation across frames (if multiple frames)\n",
    "        if len(diff_data.shape) > 2:\n",
    "            std_frame = np.std(diff_data, axis=0)\n",
    "            im2 = axes[0, 2].imshow(std_frame, cmap='plasma', aspect='auto')\n",
    "            axes[0, 2].set_title('Std Dev Across Frames')\n",
    "            plt.colorbar(im2, ax=axes[0, 2])\n",
    "            \n",
    "            # Frame-by-frame statistics\n",
    "            frame_means = [np.mean(diff_data[i]) for i in range(diff_data.shape[0])]\n",
    "            frame_stds = [np.std(diff_data[i]) for i in range(diff_data.shape[0])]\n",
    "            \n",
    "            axes[1, 0].plot(frame_means, 'b-', label='Mean')\n",
    "            axes[1, 0].set_title('Frame Statistics')\n",
    "            axes[1, 0].set_xlabel('Frame Number')\n",
    "            axes[1, 0].set_ylabel('Mean Value')\n",
    "            axes[1, 0].legend()\n",
    "            \n",
    "            ax2 = axes[1, 0].twinx()\n",
    "            ax2.plot(frame_stds, 'r-', label='Std Dev')\n",
    "            ax2.set_ylabel('Std Dev')\n",
    "            ax2.legend(loc='upper right')\n",
    "        else:\n",
    "            axes[0, 2].text(0.5, 0.5, 'Single Frame\\nNo Temporal Analysis', \n",
    "                           ha='center', va='center', transform=axes[0, 2].transAxes)\n",
    "            axes[1, 0].text(0.5, 0.5, 'Single Frame\\nNo Frame Statistics', \n",
    "                           ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        \n",
    "        # Radial profile (assuming square image)\n",
    "        if len(first_frame.shape) == 2:\n",
    "            center_y, center_x = np.array(first_frame.shape) // 2\n",
    "            y, x = np.ogrid[:first_frame.shape[0], :first_frame.shape[1]]\n",
    "            r = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n",
    "            \n",
    "            # Bin by radius\n",
    "            max_r = int(np.max(r))\n",
    "            radial_profile = []\n",
    "            radii = []\n",
    "            for i in range(0, max_r, max(1, max_r//50)):\n",
    "                mask = (r >= i) & (r < i+1)\n",
    "                if np.any(mask):\n",
    "                    radial_profile.append(np.mean(first_frame[mask]))\n",
    "                    radii.append(i)\n",
    "            \n",
    "            axes[1, 1].plot(radii, radial_profile, 'g-')\n",
    "            axes[1, 1].set_title('Radial Profile')\n",
    "            axes[1, 1].set_xlabel('Radius (pixels)')\n",
    "            axes[1, 1].set_ylabel('Mean Value')\n",
    "        \n",
    "        # Power spectrum (2D FFT)\n",
    "        fft_data = np.fft.fft2(first_frame)\n",
    "        power_spectrum = np.abs(fft_data)**2\n",
    "        axes[1, 2].imshow(np.log10(np.fft.fftshift(power_spectrum) + 1), \n",
    "                         cmap='hot', aspect='auto')\n",
    "        axes[1, 2].set_title('Power Spectrum (log)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_dir:\n",
    "            save_path = Path(save_dir) / f\"{exposure_id}_difference_analysis.png\"\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            self.logger.info(f\"Saved plot to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def compare_exposures(self, exposure_ids: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Compare statistics across multiple exposures\n",
    "        \n",
    "        Args:\n",
    "            exposure_ids: List of exposure IDs to compare\n",
    "            \n",
    "        Returns:\n",
    "            Comparison results\n",
    "        \"\"\"\n",
    "        comparison = {\n",
    "            'exposures': exposure_ids,\n",
    "            'differences': {},\n",
    "            'patches': {}\n",
    "        }\n",
    "        \n",
    "        # Compare difference statistics\n",
    "        diff_stats = []\n",
    "        for exp_id in exposure_ids:\n",
    "            if exp_id in self.exposures and self.exposures[exp_id]['differences']:\n",
    "                data = self.exposures[exp_id]['differences']['data']\n",
    "                stats = {\n",
    "                    'exposure_id': exp_id,\n",
    "                    'mean': float(np.mean(data)),\n",
    "                    'std': float(np.std(data)),\n",
    "                    'rms': float(np.sqrt(np.mean(data**2))),\n",
    "                    'shape': data.shape\n",
    "                }\n",
    "                diff_stats.append(stats)\n",
    "        \n",
    "        comparison['differences']['stats'] = diff_stats\n",
    "        \n",
    "        # Compare patch counts\n",
    "        patch_stats = []\n",
    "        for exp_id in exposure_ids:\n",
    "            if exp_id in self.exposures and self.exposures[exp_id]['patches']:\n",
    "                patches = self.exposures[exp_id]['patches']\n",
    "                for size, patch_data in patches.items():\n",
    "                    patch_stats.append({\n",
    "                        'exposure_id': exp_id,\n",
    "                        'patch_size': size,\n",
    "                        'count': patch_data['patches'].shape[0],\n",
    "                        'mean_anomaly_score': float(np.mean(patch_data['anomaly_scores'])) if patch_data['anomaly_scores'] is not None else None\n",
    "                    })\n",
    "        \n",
    "        comparison['patches']['stats'] = patch_stats\n",
    "        \n",
    "        return comparison\n",
    "    \n",
    "    def export_summary_report(self, filename: str = None):\n",
    "        \"\"\"Export a comprehensive summary report\"\"\"\n",
    "        if not filename:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"test_data_summary_{timestamp}.json\"\n",
    "        \n",
    "        report = {\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'test_directory': str(self.test_dir),\n",
    "            'summary': self.get_data_summary(),\n",
    "            'file_discovery': {\n",
    "                'difference_files': [str(f) for f in self.difference_files],\n",
    "                'patch_files': [str(f) for f in self.patch_files],\n",
    "                'temporal_files': [str(f) for f in self.temporal_files],\n",
    "                'metadata_files': [str(f) for f in self.metadata_files]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add detailed analysis for each exposure\n",
    "        if self.exposures:\n",
    "            report['detailed_analysis'] = self.analyze_differences()\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        \n",
    "        self.logger.info(f\"Summary report exported to {filename}\")\n",
    "        return filename\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Example usage of the TestDataLoader\"\"\"\n",
    "    # Setup logging\n",
    "    logging.basicConfig(level=logging.INFO, \n",
    "                       format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    # Initialize loader\n",
    "    loader = TestDataLoader(\"test\")  # or whatever your test directory is\n",
    "    \n",
    "    # Load all exposures\n",
    "    exposures = loader.load_all_exposures()\n",
    "    print(f\"Loaded {len(exposures)} exposures\")\n",
    "    \n",
    "    # Get summary\n",
    "    summary = loader.get_data_summary()\n",
    "    print(\"\\nData Summary:\")\n",
    "    print(f\"Total exposures: {summary['total_exposures']}\")\n",
    "    print(f\"Total difference frames: {summary['overall_stats']['total_difference_frames']}\")\n",
    "    print(f\"Total patches: {summary['overall_stats']['total_patches']}\")\n",
    "    print(f\"Patch sizes: {summary['overall_stats']['patch_sizes']}\")\n",
    "    print(f\"Datasets: {summary['overall_stats']['datasets']}\")\n",
    "    \n",
    "    # Analyze differences\n",
    "    if exposures:\n",
    "        first_exposure = list(exposures.keys())[0]\n",
    "        print(f\"\\nAnalyzing differences for {first_exposure}:\")\n",
    "        analysis = loader.analyze_differences(first_exposure)\n",
    "        print(f\"Shape: {analysis[first_exposure]['shape']}\")\n",
    "        print(f\"Mean: {analysis[first_exposure]['mean']:.6f}\")\n",
    "        print(f\"Std: {analysis[first_exposure]['std']:.6f}\")\n",
    "        \n",
    "        # Create plots\n",
    "        loader.plot_difference_analysis(first_exposure)\n",
    "    \n",
    "    # Export report\n",
    "    report_file = loader.export_summary_report()\n",
    "    print(f\"\\nDetailed report saved to: {report_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jpl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
